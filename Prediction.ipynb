{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f2a3cdd-5990-4283-be01-84824f406f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803759eb-63a2-4de4-a0f6-5bfe4ae061fd",
   "metadata": {},
   "source": [
    "### Task 1 - Credit Card Fraud Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c834e86-4668-4bbf-b511-1e9e87d2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.PS4_task1_training import extract_time_feats, feats, remove_irr\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_fraud_model(model_path):\n",
    "    \"\"\"\n",
    "    Loads the model using joblib\n",
    "    Params :\n",
    "    model_path (str) : Path to the  model\n",
    "\n",
    "    Returns :\n",
    "    model (Random forest) : Returns the previously trained model\n",
    "    \"\"\"\n",
    "    model = joblib.load(model_path)\n",
    "    return model\n",
    "\n",
    "def load_fraud_test_data(test_data_path):\n",
    "    \"\"\"\n",
    "    Perform feature extraction using functions from the training notebook\n",
    "    Params :\n",
    "    test_data_path (str) : Path to the testing data\n",
    "\n",
    "    Returns :\n",
    "    credit_date (df) : Dataframe with new features and irrelevant ones removed\n",
    "    \"\"\"\n",
    "    credit_data = pd.read_csv(test_data_path)# Assume CSV for simplicity\n",
    "    credit_data = extract_time_feats(credit_data)\n",
    "    credit_data = feats(credit_data)\n",
    "    credit_data = remove_irr(credit_data)\n",
    " \n",
    "\n",
    "    return credit_data\n",
    "\n",
    "def preprocess_data(test_data):\n",
    "    \"\"\"\n",
    "    Apply any standardization and split the data\n",
    "    Params :\n",
    "    test_data (df) : Dataframe of data\n",
    "\n",
    "    Returns :\n",
    "    X_scaled (df): feature dataframe that is standardized\n",
    "    y (arr) : Fraud labels\n",
    "    \"\"\"\n",
    "\n",
    "    X = test_data.drop(columns = ['is_fraud'])\n",
    "    y = test_data['is_fraud']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model\n",
    "    Params : \n",
    "    model (sklearn model) : Trained model for fraud detection\n",
    "    X_test (dataframe) : \n",
    "    y_test (array) : Labels for fraud\n",
    "    \n",
    "    Prints :\n",
    "    Classification report\n",
    "    Accuracy of the model\n",
    "    F1 of the fraud class\n",
    "    F1-avg of both classes\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_fraud = f1_score(y_test, y_pred)\n",
    "    f1_avg  = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(\"ACCURACY: \", accuracy)\n",
    "    print(\"F1-Fraud : \", f1_fraud)\n",
    "    print(\"F1-Avg : \", f1_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11911077-61dd-4e3c-b0f9-dcc7d295c1d3",
   "metadata": {},
   "source": [
    "## Task 1 Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86a20b76-e12d-424b-8a76-1d558cb54220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'cct_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "badef906-43f5-4e67-8592-57adca3555ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: Index(['amt', 'is_fraud', 'hour', 'day_of_month', 'month', 'year', 'quarter',\n",
      "       'age', 'category_cat', 'profile_cat', 'is_in_us', 'suspicious_cat',\n",
      "       'merchant_freq_encoded'],\n",
      "      dtype='object')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    697228\n",
      "           1       1.00      0.99      0.99      3579\n",
      "\n",
      "    accuracy                           1.00    700807\n",
      "   macro avg       1.00      0.99      1.00    700807\n",
      "weighted avg       1.00      1.00      1.00    700807\n",
      "\n",
      "ACCURACY:  0.9999243729015264\n",
      "F1-Fraud :  0.9925404644616467\n",
      "F1-Avg :  0.9999240922671615\n"
     ]
    }
   ],
   "source": [
    "model_path = 'task_1_model.pkl'  \n",
    "\n",
    "fraud_model = load_fraud_model(model_path)\n",
    "    \n",
    "test_data = load_fraud_test_data(test_data_path)\n",
    "X_test, y_test = preprocess_data(test_data)\n",
    "\n",
    "evaluate_model(fraud_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f2c4a-d76f-4de5-a49c-eb1e741d628a",
   "metadata": {},
   "source": [
    "### Task 2 - Human Activity Recognition Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4014dfcc-c639-4e91-a9be-b3de529f80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_2 = pd.read_csv('har_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4146e898-4eb2-4eec-a008-d9fbcae61970",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df_2.iloc[:, :-1]\n",
    "y = test_df_2.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65c10adf-321f-4588-bab2-5d5ecae7b2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu10/s7/lpr5476/miniconda3/envs/idai610/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loaded_label_encoder = joblib.load('label_encoder_task2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a0a6089-654d-416e-97a1-8b103c8d60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = loaded_label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a60b4eba-0ba4-4b93-bcfa-f1d9956f54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Macro Averaged F1 Score:\", macro_f1)\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39259d0e-26b6-4edf-bd8d-0d9ad8e7188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Macro Averaged F1 Score: 1.0\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       274\n",
      "           1       1.00      1.00      1.00       387\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00       117\n",
      "           4       1.00      1.00      1.00        17\n",
      "           5       1.00      1.00      1.00       696\n",
      "           6       1.00      1.00      1.00       122\n",
      "           7       1.00      1.00      1.00       579\n",
      "           8       1.00      1.00      1.00        59\n",
      "           9       1.00      1.00      1.00        84\n",
      "          10       1.00      1.00      1.00        94\n",
      "\n",
      "    accuracy                           1.00      2441\n",
      "   macro avg       1.00      1.00      1.00      2441\n",
      "weighted avg       1.00      1.00      1.00      2441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = joblib.load(\"pipeline_task2.pkl\")\n",
    "accuracy, macro_f1 = evaluate(loaded_pipeline, X, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d5cfc19-fb5a-4210-850b-8b5cc36890d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Macro Averaged F1-score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Macro Averaged F1-score: \", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0893a7-ef6d-462a-842b-0f21e15c4f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
